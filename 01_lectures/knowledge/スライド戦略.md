


---

## 1) まず前提：AIは「能力」ではなく「増幅器」

あなたのメモにある通り、同じAIでも

- **目的・実行方法・前提**が分かってる人 → 成功
    
- 「生産性を上げたい」だけの人 → 失敗
    

これってつまり、AIは **人の思考の質を増幅する**。

- 思考が粗い → 粗さが加速する（それっぽい破綻を量産）
    
- 思考が精密 → 精密さが加速する（検証と編集が速くなる）
    

ここが2026の“本質”。

---

## 2) 人間×AIの関係を深掘るための3層モデル

ノートの「因数分解」「明確な指示」「目的意識」を、そのまま3層にする。

### 層A：分解（因数分解）

AIに投げる前に、人間がやる仕事はこれ。

- 何を「部品」に切るか（coding / 画像 / level design / データ / QA…）
    
- 何が不確実で、何が確実か
    
- どこがボトルネックか
    

**AIは“全体設計”が苦手**。  
だから、分解できない人ほど「AIに丸投げ」になる。

---

### 層B：記述（明確な指示＝仮説・目的・制約）

あなたの図の「明確→仮説/目的/制約」はそのまま講義の核にできる。

- 目的：何を良くしたい？（面白さ？学習？売上？没入？）
    
- 仮説：なぜそれが効く？（このテンポなら気持ちいい、など）
    
- 制約：何を守る？（60fps、コスト、世界観、倫理、年齢、運用）
    

AIの出力品質は、ここでほぼ決まる。

---

### 層C：判断（目的意識＝最終責任）

ここが一番深い。  
AI時代の“人間の価値”は **判断の連続性** にある。

- 何を採用するか
    
- 何を捨てるか
    
- 何を守るか
    
- 何を優先するか
    

AIは提案できても、**責任は負えない**。  
だから「判断を放棄した瞬間」に、人はAIに使われる側になる。

---

## 3) 「AIに使われる人」問題の正体（あなたのノートの核心）

ノートの右ページにある

- PEしない
    
- 結果を鵜呑みに
    
- 自己実現の感覚が薄い
    
- 「私はどちらの人間か？」というクリティカルシンキング
    

これ、めちゃくちゃ重要。

ここで言ってる“PE”は技術論じゃなくて、**主体性のプロトコル**だと思う。

### AIに使われる状態の構造

1. 目的がない（または弱い）
    
2. 分解できない
    
3. だから指示が曖昧
    
4. 出力を評価できない
    
5. 結果だけを採用
    
6. 成功しても「自分がやった感」が残らない  
    → 自己実現が薄くなる
    

逆に言うと、

### AIを使いこなす状態の構造

1. 目的がある
    
2. 分解する
    
3. 明確に書く
    
4. 比較・検証する
    
5. 編集する
    
6. 自分の意図が作品に残る  
    → 自己実現が強くなる
    

これ、ゲーム制作に直結する。

---

## 4) 人間×AIの「役割分担」をゲーム制作で定義する

2026版の講義なら、ここを“言い切り”で置くと強い。

### AIが強い領域（得意）

- 大量案の生成（候補の発散）
    
- 既存知識の圧縮（要約・整理）
    
- パターン変換（コードの整形、説明の言い換え）
    
- テスト観点の列挙（網羅の補助）
    
- 部品の量産（アセット草案、台詞の下書き）
    

### 人間が強い領域（不可欠）

- 目的の定義（何を面白いとするか）
    
- 制約の設計（何を守るか、何を捨てるか）
    
- 体験のディレクション（間、緩急、気持ちよさ）
    
- 文化的意味づけ（誰に刺すか、文脈は何か）
    
- 最終判断と責任（採用/不採用）
    

> つまりAIは「生成」、人間は「編集と責任」。

---

## 5) 深掘りポイント：なぜ“ゲーム”がこのテーマに最適なのか

あなたが言っている「若い世代はどう学ぶ？」の答えにもなる。

ゲームには最初から、

- 目的（勝利条件）
    
- 制約（ルール、入力、fps、デバイス）
    
- 連続判断（毎フレーム、毎試行）
    
- フィードバック（面白い/つまらないが即出る）
    

が揃ってる。

だからゲームは **AI時代の人間力（分解・記述・判断）** を鍛える“実験場”。

---

## 6) 講義で刺さる「問い」（そのままワークにできる）

最後に、深掘りを“自分事化”させる問いを置くと強い。

- AIの出力を見て「良い」と言う前に、私は**評価軸**を言語化できるか？
    
- 私のゲームの面白さは、AIがいなくても説明できるか？
    
- 私はAIに「答え」を求めているか、「比較材料」を求めているか？
    
- AIの出力を採用するとき、私は何を守り、何を捨てたか言えるか？
    
- 私は「作った感」をどこで得たいのか？
    

---

## 7) 2026版の“人間×AI”の結論（短い言い切り）

最後にスライドで使える一文にすると：

- **AIは創造の代行者ではなく、創造の増幅器。**
    
- **人間の仕事は「目的」「制約」「判断」「意味づけ」。**
    
- **AIに使われるか、使いこなすかの差は、分解と明確化で決まる。**
    

---










---

# 2026章：人間×AI（全12枚）スライド案

## Slide 1｜章タイトル：人間とAIの関係はどう変わった？

**本文**

- 2026：AI（LLM）は「便利ツール」から制作の“環境”へ
    
- でも勝敗はAI性能ではなく、**使う人の思考**で決まる
    
- 今日の問い：  
    **私はAIに使われる側か？使いこなす側か？**
    

**話すメモ**

- “AIの話”に見せて、実は“人間の話”をする章です。
    

---

## Slide 2｜AIは「能力」ではなく「増幅器」

**本文**

- AIは人間の思考を増幅する
    
    - 思考が粗い → それっぽい破綻が増える
        
    - 思考が精密 → 検証と編集が加速する
        
- 同じAIでも結果が割れる理由はここ
    

**話すメモ**

- “AIが賢いほど安心”ではなく、“自分が雑だと雑が加速”する。
    

---

## Slide 3｜失敗するAI活用：生産性だけを目的にする

**本文（失敗パターン）**

- 目的が「とにかく早く」に寄りすぎる
    
- AIに“考えさせる”／丸投げする
    
- 出力を評価できず、そのまま採用する
    
- 結果：品質が不安定、責任が曖昧、チームが疲弊
    

**話すメモ**

- 生産性は大事。でも“目的”にすると壊れる。手段に戻す。
    

---

## Slide 4｜成功するAI活用：Toolとして使う

**本文（成功パターン）**

- 目的・前提・実行方法が分かっている
    
- AIは「候補生成」「比較」「検証」「下書き」に使う
    
- 人間は「編集」「決定」「責任」を持つ
    
- 結果：スピードと品質が両立する
    

**話すメモ**

- “AIが作る”じゃない。“AIで作る”。
    

---

## Slide 5｜差がつく①：因数分解（分解できる人が強い）

**本文**

- AIに投げる前に、人間がやること：**問題を部品に分ける**
    
- 例：ゲーム制作の分解
    
    - coding / 画像 / level design / データ / QA / 運用
        
- 分解できない → 全部が曖昧になり、AIが暴れる
    

**話すメモ**

- 「AIに任せたい」が出たら、まず“何を任せたいか”に分解する。
    

---

## Slide 6｜因数分解のコツ：境界とインターフェースを作る

**本文**

- 部品化とは「境界」を作ること
    
    - 何が入力で、何が出力か
        
    - 何を守るか（制約）
        
- 例：NPC会話
    
    - 設定（世界観）／目的（役割）／禁止（NG）／口調（スタイル）
        

**話すメモ**

- 部品ができるとAIが使える。部品がないとAIは“それっぽく”なるだけ。
    

---

## Slide 7｜差がつく②：明確な指示＝仮説・目的・制約

**本文**

- 明確な指示 = 情報が多いことではない
    
- 明確 = **意味が定義されている**
    
    - 仮説：なぜそれが効く？
        
    - 目的：何を良くしたい？
        
    - 制約：何を守る？何を禁止する？
        

**話すメモ**

- 指示の上手さは“言葉のうまさ”ではなく“設計のうまさ”。
    

---

## Slide 8｜曖昧→破綻／明確→意味が出る（対比例）

**本文**

- 曖昧：「面白い敵AIを作って」
    
- 明確：
    
    - 目的：初心者に“緊張”を与えたい（怖すぎはNG）
        
    - 仮説：予測可能性があると学習できて楽しい
        
    - 制約：60fps、決定性、CPU 1ms以内、理不尽行動禁止
        
    - 出力：FSM＋BTの構造図＋パラメータ表
        

**話すメモ**

- “面白い”はAIが知らない。人間が定義する。
    

---

## Slide 9｜差がつく③：目的意識（判断の連続性）

**本文**

- AIは提案できるが、責任は持てない
    
- 人間の価値は「判断の連続」にある
    
    - 何を採用するか
        
    - 何を捨てるか
        
    - 何を守るか
        
- 目的が弱いと、判断ができず“AIの言いなり”になる
    

**話すメモ**

- 目的意識 = 「迷った時のコンパス」。
    

---

## Slide 10｜AIに使われる人：自己実現が薄くなる構造

**本文**

- 目的が弱い
    
- 分解できない
    
- 指示が曖昧
    
- 評価できない
    
- 結果を鵜呑みにする
    
- 成功しても「自分が作った感」が残らない
    

**話すメモ**

- ここは叱る章じゃなくて、“危険な落とし穴の地図”として提示する。
    

---

## Slide 11｜AIを使いこなす人：自己実現が強くなる構造

**本文**

- 目的を定義する
    
- 因数分解する
    
- 仮説・目的・制約で指示する
    
- 比較・検証して編集する
    
- 意図が作品に残る
    
- 「作った感」が残り、成長が続く
    

**話すメモ**

- AI時代は“編集者の時代”。編集はクリエイターの仕事。
    

---

## Slide 12｜結論：AI時代に強いのは「設計できる人」

**本文**

- AIは創造の代行者ではなく、創造の増幅器
    
- 人間の仕事：
    
    - 目的（何を届けたいか）
        
    - 制約（何を守るか）
        
    - 判断（何を選ぶか）
        
    - 意味づけ（文化・体験・演出）
        
- 最後の問い：  
    **あなたはAIに何を任せ、何を自分が持つ？**
    

**話すメモ**

- 次の章（学び方／実践）につなげる：「じゃあどう訓練する？」へ。
    

---

## 使い方（この章を講義に差し込む位置）

2025版の流れに合わせるなら、ここはおすすめで

- 「生成AIはゲームに使える？」（2025 p.51-55相当）の直後
    
- 「個人ゲームを作ってみましょう」（実践）の直前  
    に入れると、実践の意味が一気に立ち上がります。
    

---














---

## 1. 統合の基本方針（超重要）

まず前提をはっきりさせます。

### この大量ドキュメントは「3つの役割」を持っている

|レイヤー|役割|今の姿|
|---|---|---|
|L1|**思想・哲学**|人間×AI／主体性／能力の錯覚|
|L2|**科学的・学術的裏付け**|認知科学・Arxiv・Illusion of Competence|
|L3|**技術史・実装知識**|FSM→BT→GOAP→HTN→LLM|

👉 問題は「これらが**同じ粒度で混ざっている**」こと。

---

## 2. あなたの「人間×AI 12枚」はどこに位置づくか

### 位置づけ：**L1（思想）＋L2（認知科学）の入口**

あなたが作った

> 因数分解・明確な指示・目的意識・判断  
> AIに使われる人 / 使いこなす人

これは、**この全資料群の“OS”**です。

> つまり  
> **「この思想を先に入れないと、  
> FSMもGOAPもLLMも“知識の羅列”になる」**

### だから配置はこうなる

```
[ 第0部：人間×AI（思想OS） ]  ← ★あなたの12枚
        ↓
[ 第1部：なぜ基礎が必要か（認知科学・Illusion） ]
        ↓
[ 第2部：ゲームAIの技術史（FSM〜HTN） ]
        ↓
[ 第3部：生成AI・LLMとの統合 ]
        ↓
[ 第4部：教育・カリキュラム・学び方 ]
```

---

## 3. 巨大ドキュメントを「講義向け」に再編する方法

### ❌ やってはいけない統合

- 全部スライドにする
    
- 全部読む
    
- 全部同じ重みで扱う
    

### ✅ 正解

**「思想 → 科学 → 技術 → 実践」**の一方向パイプラインにする。

---

## 4. 統合後の完成アウトライン（講義 / セミナー用）

### 【第0部】人間×AI：2026年の前提OS（★あなたの章）

**出典**：あなたのノート＋12枚スライド

- AIは能力ではなく増幅器
    
- 差は「因数分解・明確化・判断」
    
- AIに使われる構造 / 使いこなす構造
    
- 自己実現と責任の所在
    
- 「私はどちらの人間か？」
    

👉 **ここで“思想の地ならし”をする**

---

### 【第1部】なぜ「基礎がないとAIは危険か」

**対応ドキュメント**

- 生成AI主導型開発（Illusion of Competence）
    
- 認知科学・視線追跡・Comprehension-Performance Gap
    

**役割**

- 第0部の主張を**科学で裏打ち**
    

**スライド化の指針**

- Illusion of Competenceは1〜2枚の図で十分
    
- 表は削って「現象」だけ残す
    

---

### 【第2部】ゲーム開発＝AIの限界試験場

**対応ドキュメント**

- ゲーム開発における特異点
    
- 状態管理・空間論理・Unity/UEの幻覚
    

**ここで言うべき一文**

> 「ゲームは、AIが“分かったふり”できない世界」

---

### 【第3部】ゲームAI技術史＝人間が複雑さと戦った歴史

**対応ドキュメント**

- FSM → BT → GOAP → HTN → Director
    
- Halo / F.E.A.R. / Horizon / L4D
    

**重要な再解釈**

- これはAI史ではない
    
- **「人間が複雑性を管理するための思想史」**
    

👉 あなたの「因数分解」という言葉と直結する

---

### 【第4部】生成AI・LLMはどこに入るのか

**対応ドキュメント**

- Vibe Coding
    
- Prompts Are Programs Too
    
- Neuro-Symbolic AI
    
- LLM + BT / GOAP / HTN
    

**明確な線引き**

- LLM = 推論・生成・補助
    
- 決定論システム = 実行・保証・責任
    

👉 「人間×AIの役割分担」が再び回収される

---

### 【第5部】教育・学び方・進路

**対応ドキュメント**

- カリキュラム設計
    
- 思考の筋トレとしてのゲームAI
    
- サンドイッチ方式
    

**最終メッセージ**

- 産業でも研究でもいい
    
- でも共通点は  
    **「分解し、設計し、判断した経験」**
    

---

## 5. 統合後の“思想的一貫性”

この統合で一貫している軸はこれです：

> **AI時代に価値を持つのは  
> ・目的を定義できる人  
> ・問題を分解できる人  
> ・判断の責任を引き受ける人**

FSMもGOAPもLLMも、  
**全部その訓練素材**。

---

## 6. 次にやると完成度が跳ね上がる作業

ここまで来たら、次は選択肢が3つあります。

### A. 統合アウトラインを**正式な講義資料（目次＋要約）**に落とす

→ 大学・専門学校・学会提出向け

### B. **2026年版スライド構成（全体60〜90分）**を確定

→ 実際に話す用

### C. この思想を**論文・白書レベルの1本に統合**

→ 教育・研究・政策提言向け

正直に言うと、  
**この素材量と思想の深さは「B→A→C」の順が最強**。

どれからいきましょうか。



そもそも12枚というのは少なすぎます。去年のPDFを参考に今年のページ設計、ドキュメントの全体設計を、おねがいします　もう一度去年のものをはります。

了解。**12枚は“章のコア”としては良いけど、去年の107枚クラスの講義資料にするには全然足りない**。  
なので、去年PDF（107p） の構造を踏襲しつつ、あなたが書いた2026の問題意識（人間×AI／基礎教育／Vibe Codingの限界／産業変化）を組み込んだ **「2026年版：全体ページ設計（章立て＋ページ配分＋各章の中身テンプレ）」**を提示します。

---

# 0) 2026版の設計原則（去年との差分）

去年は「ゲームAIの概観＋生成AIの適用可否＋実践」だった。  
2026はここを明確に変える：

- **AIの主語を“技術”から“人間の能力差”へ**（AIは増幅器）
    
- **Vibe Coding（生成AI主導開発）を正面から扱う**
    
- **「基礎が必要」の根拠を “認知科学＋技術的特異点（ゲーム）” で支える**
    
- 実践は「個人ゲーム」だけでなく、**産業レベル（工程・QA・運用）**に接続
    

---

# 1) 2026年版：全体アウトライン（120枚前後の目安）

去年の107枚より少し増やして、**“2026の主張”を追加しても薄くならない**構成にします。

## 章構成（8章 + 付録）

1. 導入：2026の変化（10p）
    
2. ゲームとAIの関係（GPU/リアルタイム） (12p)
    
3. ゲームAIの基礎（ルール→FSM→A*→BT→RL）(20p)
    
4. 象徴事例（不完全情報／Suphx枠＋2026版の追加事例）(12p)
    
5. 生成AI・Vibe Coding：何が変わり何が壊れるか (20p)
    
6. 人間×AI：差がつく能力（因数分解・明確化・判断）(16p)
    
7. ゲーム制作の再設計：工程・QA・運用・産業変化 (16p)
    
8. 学び方と進路：研究も産業も、作って貢献する (12p)  
    付録：参考リンク・用語・演習課題 (5p)
    

合計：**123p前後**（※調整可能）

---

# 2) 章ごとのページ設計（去年対応表つき）

去年PDFの節目（目次が何度も出る）を“章の区切り”として使い、差し替え・増設箇所を明確にします。

---

## 第1章 導入：2026の変化（10p）

**去年対応：p.1〜6（タイトル〜目次）**  
**2026版の追加**：Vibe Coding / 産業変化 / 人間の価値

- 1 タイトル（2026サブタイトル追加）
    
- 2 使うリンク（GitHub/デモ/アンケート）※去年同様
    
- 3 自己紹介（短く）
    
- 4 問題提起：2025→2026で何が変わった？
    
- 5 生成AI主導開発（Vibe Coding）の登場
    
- 6 今日の結論（先出し）：AIは増幅器／人間は判断者
    
- 7 今日のゴール：①理解 ②作れる ③学び続けられる
    
- 8 今日のロードマップ（目次）
    
- 9 ワーク①：あなたはAIをどう使ってる？（挙手機能/wooclap）
    
- 10 章の導入スライド（「ゲームはAI時代の最良の教材」）
    

---

## 第2章 ゲームとAIの関係（GPU/リアルタイム）（12p）

**去年対応：p.7〜11＋関連**

去年の「DirectX→GPU→NN」の流れは強いので残す。  
2026は「なぜリアルタイムがLLMと衝突するか」に接続させる。

- 1 ゲームにはグラフィックスが必要（DirectX）
    
- 2 レイトレーシングの意味
    
- 3 GPUの行列計算→AI基盤
    
- 4 “リアルタイム制約”の4条件（遅延・決定性・コスト・デバッグ）
    
- 5 LLMが苦手な理由①：レイテンシ
    
- 6 LLMが苦手な理由②：非決定性
    
- 7 LLMが苦手な理由③：状態保持の弱さ（ここは後で回収）
    
- 8 だから「ゲームはAIの限界が見える」
    
- 9 まとめ（次章へ）
    

---

## 第3章 ゲームAI基礎：アルゴリズムは“部品”（20p）

**去年対応：p.12〜29（なぜAI必要→手法列挙→リスク）**  
ここを2026版で一番“講義向け”に再設計する。

**構成**：「目的→部品→使い分け→リスク」

- 1 なぜゲームにAIが必要？（敵AIの起点）
    
- 2 ゲームAIの歴史（チェス/囲碁/麻雀等の系譜）
    
- 3 状態空間・ゲーム木（難易度の定義）
    
- 4 不完全情報ゲーム（情報集合）
    

**AI実装の部品（各2p×6=12p）**

- 5 ルールベース：予測可能性＝面白さ
    
- 6 FSM：決定論とデバッグ性
    
- 7 A*：空間と探索（ゲームの「論理の骨」）
    
- 8 Behavior Tree：複雑性管理
    
- 9 機械学習：データで適応
    
- 10 強化学習：コストが高い／でも象徴的
    

**リスク（4p）**

- 11 ゲームバランス崩壊
    
- 12 意図とズレる
    
- 13 コスト／複雑化
    
- 14 プレイヤー行動固定化
    

---

## 第4章 象徴事例：不完全情報と“意思決定”（12p）

**去年対応：p.16〜21（Suphx＋模倣学習）**

ここは2026では「人間の判断」と接続する章にする。

- 1 Suphxとは（実績）
    
- 2 有段者評価（リアリティ）
    
- 3 不完全情報で勝つ＝仮説・予測・推論
    
- 4 現実世界への接続（自動運転・金融）
    
- 5 模倣学習（Falken）＝学びの設計
    
- 6 2026追加：ゲームAI＝“判断の筋トレ”という再定義
    
- 7 小まとめ（次：生成AIへ）
    

---

## 第5章 生成AI・Vibe Coding：何が変わり、何が壊れるか（20p）

**去年対応：p.51〜55（生成AI使える？）**  
ここを2026版の“中核章”として拡張。

**前半（8p）：去年の主張をアップデート**

- 1 パックマンゴーストの本質（予測可能性/即時性/効率）
    
- 2 汎用LLMそのままの問題（レイテンシ/一貫性/コスト）
    
- 3 生成AIは発展途上／本番適用は慎重
    
- 4 2026：それでも浸透した（制作支援の標準化）
    
- 5 “生成AIゲーム”というジャンル整理（無限生成/動的対話/世界モデル）
    
- 6 生成AIゲームの落とし穴（制約がないとゲームにならない）
    
- 7 結論：生成＝面白さではない（体験設計が本体）
    
- 8 ここで“Vibe Coding”へ
    

**後半（12p）：Vibe Codingの功罪（あなたの長文ドキュメントを講義化）**

- 9 Vibe Codingとは何か（定義）
    
- 10 MVPは作れる、製品は別（ここで“生成的負債”）
    
- 11 生成的負債：構造/幻覚的複雑性/省略（チェック観点）
    
- 12 セキュリティ・品質保証（ゲームだと被害が直撃）
    
- 13 「プロンプト＝プログラム」：分解・抽象化・デバッグ
    
- 14 初学者の罠：Illusion of Competence（能力の錯覚）
    
- 15 Comprehension-Performance Gap（理解と成果の分離）
    
- 16 だから基礎が必要（次章：人間×AIへ橋渡し）
    
- 17 ワーク②：あなたは今どこが弱い？（分解/明確化/判断）
    
- 18 章まとめ
    

---

## 第6章 人間×AI：差がつく能力（16p）

ここで「12枚」を**章の中心8枚**にして、前後に“導入・ワーク・まとめ”を足して16枚にする。

- 1 章タイトル：人間とAIの関係（2026）
    
- 2 AIは増幅器（再掲）
    
- 3 失敗/成功（対比）
    
- 4 因数分解（coding/画像/level/データ）
    
- 5 明確な指示＝仮説/目的/制約
    
- 6 目的意識＝判断の連続
    
- 7 AIに使われる人（構造）
    
- 8 AIを使いこなす人（構造）
    
- 9 “自己実現”の話（作った感が残る設計）
    
- 10 クリエイターの仕事：意味づけ/演出/文化
    
- 11 ワーク③：曖昧プロンプト→仕様化（5分）
    
- 12 ワーク③：仕様→AI出力→レビュー観点（5分）
    
- 13 レビュー観点テンプレ（性能/保守/安全/体験）
    
- 14 まとめ（次：制作工程の再設計）
    

---

## 第7章 ゲーム制作の再設計：工程・QA・運用・産業変化（16p）

**去年対応：制作支援AI/QA/制作支援（p.43〜49, 99〜102）**  
ここを「産業レベルの変化」に昇華させる。

- 1 「敵AI」だけじゃない（ゲームそのものを開発するAI）
    
- 2 In-Game / Out-Game / Creative / Test（分類）
    
- 3 それぞれの例（表をアップデート）
    
- 4 2026：制作工程が“短周期化”
    
- 5 企画：LLMでアイデア展開（去年のKIT Explorer）
    
- 6 実装：AIコード支援＋設計が必須（去年の基本設計）
    
- 7 データ駆動設計：ロジックとコンテンツ分離
    
- 8 QA：AIテストの現実（自動プレイ）
    
- 9 運用：コミュニティ/サポート/チート対策（Out-Gameを拡張）
    
- 10 役割の変化：作る→選ぶ→編集→保証
    
- 11 産業の変化：小規模チームが勝てる領域、逆に難しくなる領域
    
- 12 章まとめ
    

---

## 第8章 学び方と進路：研究も産業も、作って貢献する（12p）

**去年対応：振り返り＋学生へのメッセージ（p.105〜106）**  
ここを2026で「学びの設計」に寄せる。

- 1 振り返り（去年の観点を更新）
    
- 2 ゲームは実験場（境界・制約・制御された複雑さ）
    
- 3 学びの型：Human→AI→Human（サンドイッチ方式）
    
- 4 “苦闘”の価値：考える時間を奪わない
    
- 5 学ぶべき基礎：アルゴリズム/データ構造/デバッグ/英語
    
- 6 2つのPath：産業／研究
    
- 7 研究例：ゲームAI・シミュレーション・QA・エージェント
    
- 8 最後のメッセージ：どちらでもいい、作って公開しよう
    
- 9 付録へ（リンク集）
    

---

# 3) 2026版の「目次ページ」案（去年形式を踏襲）

去年は目次ページが節目に何度も出て“今どこ？”が分かりやすい。  
2026も同じにして、各章頭に “章タイトル＋サブ問い” を置く。

例：章頭スライドのフォーマット

- 章タイトル
    
- 今日の問い（1行）
    
- キーワード（3つ）
    
- ここまでのつながり（矢印で1行）
    

---

# 4) まず最初に作るべき「ページの骨」

ここまでが全体設計。次にあなたが欲しいのはたぶんこれ：

- **各ページに何を書くか**（見出しと箇条書き）
    
- どのページを去年から流用するか
    
- どのページを差し替えるか
    

なので、次のステップとして **「ページ一覧（p.1〜p.123）をタイトルだけで埋めた“台本”」**を作れます。

---

## いまこの場で出せる“即戦力”として

次のどちらが良い？

1. **p.1〜p.30まで**（導入〜基礎前半）を、ページタイトル＋要点で具体化して出す


了解。**2026版 p.1〜p.30（導入〜基礎前半）**を、去年の流れを踏襲しつつ具体化します。  
形式は「ページタイトル＋要点（そのままスライド本文に落とせる粒度）」で書きます。  
（去年のPDFの導入〜基礎導線を参考にしています ）

---

# 2026版 スライド設計：p.1〜p.30（導入〜基礎前半）

## p.1 タイトル

- AI技術の活用（ゲームとAI）2026
    
- サブ：LLM時代の「作り方」と「人間の役割」
    

## p.2 今日使うリンク / 参加導線

- 講義中のリンク（アンケート / GitHub / デモ / 資料）
    
- QRコード（去年p.2相当）
    

## p.3 自己紹介（最短）

- 役割 / 経歴（ゲーム×AI×教育）
    
- 今日話す立場：現場と教育の橋渡し
    

## p.4 1年で何が変わった？（2025→2026）

- LLMが浸透：個人→チーム→産業
    
- “タスク自動化”から“工程再設計”へ
    
- でもゲームは「体験設計」が本体
    

## p.5 Vibe Coding（バイブコーディング）とは

- 自然言語で雰囲気→AIがコード→人間が監督
    
- できること：MVPの爆速化
    
- 危ないこと：理解しないまま進む
    

## p.6 今日の結論（先出し）

- AIは「能力」ではなく「増幅器」
    
- 差がつく力：**因数分解／明確化／判断**
    
- ゴール：AIに使われる人→使いこなす人へ
    

## p.7 今日のロードマップ（目次）

- 1. ゲームとAIの関係（GPU/リアルタイム）
        
- 2. ゲームAIの基礎（部品）
        
- 3. 生成AIはどこに入る？
        
- 4. 人間の役割と学び方
        

## p.8 ワーク0（30秒）

- 質問：いまAIをどこで使ってる？
    
    - 企画 / コード / 画像 / 学習 / 未使用
        
- 目的：受講者の分布把握
    

## p.9 ゲームとAI（章扉）

- 視点：ゲームはAIの“応用”ではなく“加速装置”
    
- 次：GPUの話へ
    

---

## p.10 ゲームにはリアルタイムグラフィックスが必要

- DirectX等：ゲームが要求した低レイヤ性能
    
- ここが後にAI計算基盤に接続（去年p.7系）
    

## p.11 リアルタイムレイトレーシング（例で納得）

- “それっぽい”から“シミュレーション”へ
    
- リアルタイム化が技術を押し上げた（去年p.8系）
    

## p.12 GPUが必要な理由（ゲーム→AIへの橋）

- 大量の行列計算／並列計算
    
- CPUでは間に合わない → GPU文化が育つ（去年p.10系）
    

## p.13 GPU×機械学習（加速の本質）

- NN＝行列乗算の塊
    
- GPUの特性と一致（去年p.11系）
    

## p.14 ここで重要：ゲームは“リアルタイム制約”の塊

- 制約①レイテンシ（ms単位）
    
- 制約②決定性（同条件で同結果）
    
- 制約③コスト（常時推論は高い）
    
- 制約④デバッグ（原因追跡できる必要）
    

## p.15 LLMがゲーム実行時に難しい理由（4つの衝突）

- レイテンシ：API/推論待ち
    
- 非決定性：同入力でブレる
    
- 状態：長期整合性が苦手
    
- 保証：性能・安全・公平の担保が難しい
    

## p.16 だから「ゲームはAIの限界が見える」

- Webアプリよりシビア（状態・リアルタイム・空間）
    
- だから教材として強い
    
- 次：ゲームにAIが必要な理由へ
    

## p.17 なぜゲームにAIが必要？

- 代表：敵AI（対戦相手の演出）
    
- でも今はそれだけじゃない（伏線）（去年p.12系）
    

## p.18 ゲームAIの見取り図（目的で整理）

- ①敵（手応え・学習可能性）
    
- ②仲間（協力・補助）
    
- ③ゲーム全体（難易度・演出・監督）
    
- ④制作（生成・テスト・運用）
    

---

## p.19 ゲームAIの歴史：なぜ研究者はゲームを選んだか

- ルールが明確／観測可能／反復できる
    
- チェス・囲碁・麻雀など（去年p.13系）
    

## p.20 AIにとっての難しさ ≠ 人間の難しさ

- 状態空間複雑性／ゲーム木複雑性
    
- “探索の爆発”が起きる（去年p.14系）
    

## p.21 完全情報ゲーム vs 不完全情報ゲーム

- 見えない情報＝推論が必要
    
- 現実世界に近いのは不完全情報（去年p.15系）
    

## p.22 ここで回収：人間の仕事も“不完全情報下の意思決定”

- 仮説・予測・推論・曖昧な判断
    
- AI時代ほど、この力が重要（次章への伏線）
    

## p.23 「AI実装の部品」を学ぶ意味（2026の言い方）

- 目的：AIを賢くするため、ではない
    
- 目的：**因数分解できる人**になるため
    
- 部品＝選択肢／設計の語彙
    

---

## p.24 敵AIの代表的テクニック（全体俯瞰）

- ルール / FSM / A* / BT / ML / RL（一覧）
    
- これを次のページから“部品として”分解して説明（去年p.22系）
    

## p.25 ルールベースAI（最小で強い）

- 良さ：軽い／決定的／予測可能＝学習できる
    
- 弱さ：読まれる
    
- 例：Pac-Man（触れるだけでOK）
    

## p.26 FSM（有限状態機械）：ゲームAIの骨格

- 状態：待機/追跡/攻撃/逃走
    
- 遷移条件：if〜
    
- 良さ：デバッグ容易、意図を固定できる
    
- 罠：状態爆発（ここは後でBTに繋ぐ）
    

## p.27 パスファインディング（A*）：空間を論理にする

- マップ＝グラフ
    
- コスト＋ヒューリスティック
    
- 良さ：空間推論を“保証”できる
    
- ここで「LLMは可解性保証が苦手」を軽く示唆
    

## p.28 Behavior Tree：複雑さを壊さず拡張する

- Sequence/Selector
    
- モジュール化・再利用
    
- “状態爆発”の対抗策
    

## p.29 機械学習AI：適応の入口

- データからパターンを学ぶ
    
- 良さ：人の行動に合わせられる
    
- 弱さ：データ偏り／説明しづらい
    

## p.30 強化学習：強いがコストが高い

- 試行錯誤＋報酬
    
- 良さ：未知環境にも強い
    
- 代償：学習コスト・運用コスト
    
- 次：実例（麻雀AIなど）へ繋ぐ導線
    

---

## 次（p.31〜）の予告

p.31以降は、去年の流れだと

- AIと人の関係の拡張
    
- Suphxなど象徴事例
    
- 生成AI（使える？）  
    に入っていきます。
    

---

このp.1〜p.30をベースに、次はどちらで進めるのが良い？

1. **p.31〜p.60**（象徴事例→生成AI→個人制作導入まで）も同じ粒度で続ける
    
2. ここまでを「スライド本文（日本語の完成文章）」にして、話すメモ込みで整える





了解。**2026版 p.1〜p.30（導入〜基礎前半）**を、去年の流れを踏襲しつつ具体化します。  
形式は「ページタイトル＋要点（そのままスライド本文に落とせる粒度）」で書きます。  
（去年のPDFの導入〜基礎導線を参考にしています ）

---

# 2026版 スライド設計：p.1〜p.30（導入〜基礎前半）

## p.1 タイトル

- AI技術の活用（ゲームとAI）2026
    
- サブ：LLM時代の「作り方」と「人間の役割」
    

## p.2 今日使うリンク / 参加導線

- 講義中のリンク（アンケート / GitHub / デモ / 資料）
    
- QRコード（去年p.2相当）
    

## p.3 自己紹介（最短）

- 役割 / 経歴（ゲーム×AI×教育）
    
- 今日話す立場：現場と教育の橋渡し
    

## p.4 1年で何が変わった？（2025→2026）

- LLMが浸透：個人→チーム→産業
    
- “タスク自動化”から“工程再設計”へ
    
- でもゲームは「体験設計」が本体
    

## p.5 Vibe Coding（バイブコーディング）とは

- 自然言語で雰囲気→AIがコード→人間が監督
    
- できること：MVPの爆速化
    
- 危ないこと：理解しないまま進む
    

## p.6 今日の結論（先出し）

- AIは「能力」ではなく「増幅器」
    
- 差がつく力：**因数分解／明確化／判断**
    
- ゴール：AIに使われる人→使いこなす人へ
    

## p.7 今日のロードマップ（目次）

- 1. ゲームとAIの関係（GPU/リアルタイム）
        
- 2. ゲームAIの基礎（部品）
        
- 3. 生成AIはどこに入る？
        
- 4. 人間の役割と学び方
        

## p.8 ワーク0（30秒）

- 質問：いまAIをどこで使ってる？
    
    - 企画 / コード / 画像 / 学習 / 未使用
        
- 目的：受講者の分布把握
    

## p.9 ゲームとAI（章扉）

- 視点：ゲームはAIの“応用”ではなく“加速装置”
    
- 次：GPUの話へ
    

---

## p.10 ゲームにはリアルタイムグラフィックスが必要

- DirectX等：ゲームが要求した低レイヤ性能
    
- ここが後にAI計算基盤に接続（去年p.7系）
    

## p.11 リアルタイムレイトレーシング（例で納得）

- “それっぽい”から“シミュレーション”へ
    
- リアルタイム化が技術を押し上げた（去年p.8系）
    

## p.12 GPUが必要な理由（ゲーム→AIへの橋）

- 大量の行列計算／並列計算
    
- CPUでは間に合わない → GPU文化が育つ（去年p.10系）
    

## p.13 GPU×機械学習（加速の本質）

- NN＝行列乗算の塊
    
- GPUの特性と一致（去年p.11系）
    

## p.14 ここで重要：ゲームは“リアルタイム制約”の塊

- 制約①レイテンシ（ms単位）
    
- 制約②決定性（同条件で同結果）
    
- 制約③コスト（常時推論は高い）
    
- 制約④デバッグ（原因追跡できる必要）
    

## p.15 LLMがゲーム実行時に難しい理由（4つの衝突）

- レイテンシ：API/推論待ち
    
- 非決定性：同入力でブレる
    
- 状態：長期整合性が苦手
    
- 保証：性能・安全・公平の担保が難しい
    

## p.16 だから「ゲームはAIの限界が見える」

- Webアプリよりシビア（状態・リアルタイム・空間）
    
- だから教材として強い
    
- 次：ゲームにAIが必要な理由へ
    

## p.17 なぜゲームにAIが必要？

- 代表：敵AI（対戦相手の演出）
    
- でも今はそれだけじゃない（伏線）（去年p.12系）
    

## p.18 ゲームAIの見取り図（目的で整理）

- ①敵（手応え・学習可能性）
    
- ②仲間（協力・補助）
    
- ③ゲーム全体（難易度・演出・監督）
    
- ④制作（生成・テスト・運用）
    

---

## p.19 ゲームAIの歴史：なぜ研究者はゲームを選んだか

- ルールが明確／観測可能／反復できる
    
- チェス・囲碁・麻雀など（去年p.13系）
    

## p.20 AIにとっての難しさ ≠ 人間の難しさ

- 状態空間複雑性／ゲーム木複雑性
    
- “探索の爆発”が起きる（去年p.14系）
    

## p.21 完全情報ゲーム vs 不完全情報ゲーム

- 見えない情報＝推論が必要
    
- 現実世界に近いのは不完全情報（去年p.15系）
    

## p.22 ここで回収：人間の仕事も“不完全情報下の意思決定”

- 仮説・予測・推論・曖昧な判断
    
- AI時代ほど、この力が重要（次章への伏線）
    

## p.23 「AI実装の部品」を学ぶ意味（2026の言い方）

- 目的：AIを賢くするため、ではない
    
- 目的：**因数分解できる人**になるため
    
- 部品＝選択肢／設計の語彙
    

---

## p.24 敵AIの代表的テクニック（全体俯瞰）

- ルール / FSM / A* / BT / ML / RL（一覧）
    
- これを次のページから“部品として”分解して説明（去年p.22系）
    

## p.25 ルールベースAI（最小で強い）

- 良さ：軽い／決定的／予測可能＝学習できる
    
- 弱さ：読まれる
    
- 例：Pac-Man（触れるだけでOK）
    

## p.26 FSM（有限状態機械）：ゲームAIの骨格

- 状態：待機/追跡/攻撃/逃走
    
- 遷移条件：if〜
    
- 良さ：デバッグ容易、意図を固定できる
    
- 罠：状態爆発（ここは後でBTに繋ぐ）
    

## p.27 パスファインディング（A*）：空間を論理にする

- マップ＝グラフ
    
- コスト＋ヒューリスティック
    
- 良さ：空間推論を“保証”できる
    
- ここで「LLMは可解性保証が苦手」を軽く示唆
    

## p.28 Behavior Tree：複雑さを壊さず拡張する

- Sequence/Selector
    
- モジュール化・再利用
    
- “状態爆発”の対抗策
    

## p.29 機械学習AI：適応の入口

- データからパターンを学ぶ
    
- 良さ：人の行動に合わせられる
    
- 弱さ：データ偏り／説明しづらい
    

## p.30 強化学習：強いがコストが高い

- 試行錯誤＋報酬
    
- 良さ：未知環境にも強い
    
- 代償：学習コスト・運用コスト
    
- 次：実例（麻雀AIなど）へ繋ぐ導線
    

---

## 次（p.31〜）の予告

p.31以降は、去年の流れだと

- AIと人の関係の拡張
    
- Suphxなど象徴事例
    
- 生成AI（使える？）  
    に入っていきます。
    

---

このp.1〜p.30をベースに、次はどちらで進めるのが良い？

1. **p.31〜p.60**（象徴事例→生成AI→個人制作導入まで）も同じ粒度で続ける
    
2. ここまでを「スライド本文（日本語の完成文章）」にして、話すメモ込みで整える
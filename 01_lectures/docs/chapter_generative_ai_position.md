# 第3部：生成AI・LLMの位置づけ

何が新しく、何が変わらないか

## 序：生成AIは「革命」か「進化」か

- 2022年11月：ChatGPT公開
- 2ヶ月で1億ユーザー突破（史上最速）
- 「AIが人間の仕事を奪う」という議論の再燃
- しかし、技術史の視点で見ると何が見えるか

## 第1章：生成AIの技術的基盤

### 1.1 Transformerアーキテクチャ（2017年）

- 論文：Vaswani et al. (2017) "Attention Is All You Need"
- Google Brainの研究チームが発表
- 従来のRNN/LSTMの限界を突破
- 並列計算が可能に → 大規模化への道

### 1.2 Self-Attentionの仕組み

- Query, Key, Valueの3つのベクトル
- 各トークンが他の全トークンとの関連度を計算
- Attention(Q,K,V) = softmax(QK^T / √d_k) V
- 「文脈」を数学的に捉える手法

### 1.3 なぜTransformerが革新的だったか

- RNNの問題：逐次処理（並列化困難）
- LSTMの問題：長距離依存の学習が困難
- Transformerの解決策
- 全てのトークン間の関係を一度に計算
- 位置エンコーディングで順序を保持
- GPUの並列計算能力を最大活用

### 1.4 スケーリング則（Scaling Laws）

- 論文：Kaplan et al. (2020) "Scaling Laws for Neural Language Models"
- 発見：モデルサイズ、データ量、計算量を増やすと予測可能に性能向上
- パラメータ数 10x → 性能は一定比率で向上
- これが「大きければ大きいほど良い」の根拠

### 1.5 GPTシリーズの進化

- GPT-1 (2018)：1.17億パラメータ
- GPT-2 (2019)：15億パラメータ
- GPT-3 (2020)：1750億パラメータ
- GPT-4 (2023)：推定1兆以上（非公開）
- パラメータ数は4年で1万倍以上に

## 第2章：LLMは何ができて何ができないか

### 2.1 LLMの本質：確率的言語モデル

- 入力：トークン列 [t1, t2, ..., tn]
- 出力：次のトークンの確率分布 P(t_{n+1} | t1, ..., tn)
- 「最も確率の高い続き」を生成
- これは「理解」ではなく「予測」

### 2.2 In-Context Learning（文脈内学習）

- Few-shot learning：数例を見せるだけで新しいタスクに対応
- 論文：Brown et al. (2020) "Language Models are Few-Shot Learners"
- 従来のML：タスクごとに再学習が必要
- LLM：プロンプトに例を含めるだけ
- これが「汎用性」の源泉

### 2.3 Chain-of-Thought（思考の連鎖）

- 論文：Wei et al. (2022) "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"
- 発見：「ステップバイステップで考えて」と指示すると推論精度が向上
- 例：「答えは42」より「まず条件を整理すると...したがって42」
- 中間ステップの生成が推論を改善

### 2.4 LLMが得意なこと

- 自然言語の生成・変換・要約
- パターンマッチングと類推
- 知識の検索と統合
- 文脈に応じた応答生成
- コード生成（自然言語→プログラム）

### 2.5 LLMが苦手なこと

- 厳密な論理推論
- 数学的計算（特に多桁の計算）
- 最新情報へのアクセス
- 長期的な一貫性の維持
- 「知らない」ことを知ること（メタ認知）

### 2.6 幻覚（Hallucination）問題

- 定義：事実と異なる情報をもっともらしく生成する現象
- 原因：確率的生成の本質的性質
- LLMは「正しいか」ではなく「ありそうか」で出力
- 例：存在しない論文の引用、架空の統計データ

### 2.7 幻覚の具体例

- 「アインシュタインの1987年の論文では...」（1955年に死去）
- 存在しないAPIやライブラリの提案
- 架空の法律や規則の引用
- 実在しない人物の経歴
- これらは「嘘」ではなく「確率的に生成された誤り」

## 第3章：生成AIとゲームAIの比較

### 3.1 根本的な設計思想の違い

- ゲームAI：決定論的、再現可能、検証可能
- 生成AI：確率的、創造的、予測不能
- ゲームAI：「正しく動く」ことが最優先
- 生成AI：「それらしく見える」ことが最優先

### 3.2 レイテンシの違い

- ゲームAI：16.7ms以内（60FPS）
- 生成AI：100ms〜数秒
- ゲームAI：毎フレーム決定が必要
- 生成AI：応答を待つ余裕がある場面向け

### 3.3 状態管理の違い

- ゲームAI：明示的な状態管理（FSM、BT、Blackboard）
- 生成AI：暗黙的な状態（コンテキストウィンドウ）
- ゲームAI：状態遷移が追跡可能
- 生成AI：なぜその出力になったか説明困難

### 3.4 エラーの性質の違い

- ゲームAI：バグは再現可能、修正可能
- 生成AI：エラーは確率的、同じ入力で異なるエラー
- ゲームAI：テストでバグを検出可能
- 生成AI：全ての出力をテストすることは不可能

### 3.5 責任の所在の違い

- ゲームAI：開発者がロジックを書く→開発者の責任
- 生成AI：モデルが出力を生成→責任の所在が曖昧
- ゲームAI：「なぜそう動いたか」を説明できる
- 生成AI：説明可能性（Explainability）が低い

## 第4章：Vibe Codingの功罪

### 4.1 Vibe Codingとは何か

- 提唱者：Andrej Karpathy（元Tesla AI責任者、OpenAI創設メンバー）
- 2024年の発言がきっかけで広まる
- 定義：AIに自然言語で指示し、生成されたコードを「監督」するスタイル
- 細かい実装詳細より「雰囲気」や「意図」を伝える

### 4.2 Karpathyの原文

- "There's a new kind of coding emerging"
- "where you fully give in to the vibes"
- "embrace exponentials, and forget that the code even exists"
- 「コードの存在を忘れて、指数関数的な成長を受け入れる」

### 4.3 Vibe Codingの適用領域

- プロトタイプ作成（MVP）
- 使い捨てスクリプト
- 学習・実験目的のコード
- 個人プロジェクト
- 「動けばいい」場面

### 4.4 Vibe Codingが有効な理由

- 開発速度の劇的な向上
- アイデアの迅速な検証
- 初学者でも形にできる
- 試行錯誤の回数が増える
- 「作れない→作れる」の壁を下げる

### 4.5 Vibe Codingの危険性

- コードを理解していない状態での「完成」
- 隠れたバグの蓄積
- セキュリティ脆弱性の見落とし
- 技術的負債の急速な蓄積
- 「なぜ動くか分からない」コードの量産

### 4.6 能力の錯覚（Illusion of Competence）

- 研究：Roediger & Karpicke (2006)
- 定義：実際には理解していないのに理解したと思い込む現象
- LLM時代に特に顕著
- タスクは完了した
- コードは動く
- しかし「なぜ動くか」は説明できない

### 4.7 研究：AIツールと学習効果

- Bastani et al. (2024) "Generative AI Can Harm Learning"
- 発見：AIチューターを使った学生は、使わなかった学生より成績が低下
- 原因：AIが「考える」プロセスを代行してしまう
- 「自分で苦労する」経験が学習に不可欠

### 4.8 生成的負債（Generative Debt）

- 技術的負債（Technical Debt）の拡張概念
- 定義：理解なく生成されたコードが蓄積する問題
- 特徴
- 負債の存在に気づきにくい
- 問題が表面化するまで時間がかかる
- 返済（修正）に元の生成より多くの時間がかかる

### 4.9 生成的負債の具体例

- AIが生成した「動くけど非効率な」コード
- 冗長なデータベースクエリ
- メモリリークを含むコード
- セキュリティホールを含む認証ロジック
- これらは「動く」ので見落とされやすい

## 第5章：何が新しく、何が変わらないか

### 5.1 新しいこと：自然言語インターフェース

- コードを書かずにプログラムを作れる可能性
- 専門知識なしで専門的なタスクに取り組める
- アイデアから実装までの距離が縮まる
- これは真に革新的

### 5.2 新しいこと：Few-shot適応

- 数例を見せるだけで新しいタスクに対応
- タスクごとの再学習が不要
- 汎用的な「能力」の実現に近づいた
- これも革新的

### 5.3 新しいこと：創造的補助

- アイデアの壁打ち相手
- 多様な選択肢の提示
- 異なる視点からのフィードバック
- 創造プロセスの加速

### 5.4 変わらないこと：決定論性の必要性

- ゲームは毎フレーム同じ入力に同じ出力が必要
- 金融システムは監査可能性が必要
- 医療システムは再現可能性が必要
- 生成AIはこれを満たさない

### 5.5 変わらないこと：状態管理の重要性

- 複雑なシステムは状態を追跡する必要がある
- LLMのコンテキストウィンドウは有限
- 長期的な一貫性は依然として難しい
- 明示的な状態管理は消えない

### 5.6 変わらないこと：検証の必要性

- AIが生成したコードも検証が必要
- テスト、レビュー、監査
- むしろ重要性は増している
- 「AIが書いた」は品質保証にならない

### 5.7 変わらないこと：人間の判断

- 採用するかどうかを決めるのは人間
- 捨てる判断をするのは人間
- 優先順位をつけるのは人間
- 責任を取るのは人間

### 5.8 変わらないこと：基礎の重要性

- AIを使いこなすには基礎知識が必要
- デバッグ能力はAI時代に一層重要
- アルゴリズムの理解がないと評価できない
- 「AIがやってくれる」の限界

## 第6章：ゲーム開発における生成AIの現実的な活用

### 6.1 In-Game AI（ゲーム内AI）での活用

- NPCとの自然言語対話
- 動的なストーリー生成
- プレイヤー行動への適応的応答
- ただし、レイテンシと一貫性の問題がある

### 6.2 Out-Game AI（ゲーム外AI）での活用

- アセット生成（テクスチャ、3Dモデル、音楽）
- シナリオ・ダイアログの草案作成
- バグレポートの分析
- ドキュメント生成

### 6.3 QAと自動テストでの活用

- 自動プレイテスト
- バグの自動検出
- テストケースの生成
- カバレッジの向上

### 6.4 コード生成での活用

- ボイラープレートコードの生成
- 単純なスクリプトの作成
- リファクタリングの提案
- ただし、レビューは必須

### 6.5 ハイブリッドアーキテクチャ

- LLM（創造性・柔軟性）
- ルールベース（安全性・一貫性）
- 状態管理システム（整合性・追跡可能性）
- 3層構造での活用が現実解

### 6.6 具体例：NPCの対話システム

- LLMが応答候補を生成
- ルールエンジンがゲーム状態との整合性をチェック
- 整合性のない応答は修正または却下
- 有効な応答のみをプレイヤーに提示

### 6.7 具体例：動的クエスト生成

- LLMがクエスト案を生成
- ゲームロジックが実行可能性をチェック
- 必要なリソースが存在するか
- 報酬バランスは適切か
- プレイヤーに提示

## 第7章：まとめ：生成AIの位置づけ

### 7.1 生成AIは「ツール」である

- 万能ではない
- 適用領域がある
- 限界がある
- 人間が使いこなすもの

### 7.2 生成AIは「増幅器」である

- 思考が粗い → 粗さが拡大
- 思考が精密 → 精密さが加速
- AIは人間の能力を増幅する
- 元の能力がないものは増幅できない

### 7.3 ゲームAI技術は消えない

- 決定論的AIは依然として必要
- FSM、BT、GOAPは現役
- LLMは「追加」であり「置換」ではない
- 使い分けの知識が重要

### 7.4 基礎はより重要になる

- AIを評価するには基礎知識が必要
- デバッグ能力の重要性は増す
- 「なぜそうなるか」を理解する力
- 批判的思考（Critical Thinking）

### 7.5 最終メッセージ

- 新しい技術に飛びつく前に、何が新しく何が変わらないかを見極める
- 技術史を学ぶことで、現在の位置を理解できる
- 変わらないものを大切にしながら、新しいものを取り入れる
- これが技術者としての姿勢
